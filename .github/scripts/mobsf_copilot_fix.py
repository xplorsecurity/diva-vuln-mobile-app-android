import json
import os
import subprocess
import requests
import time

# Configuration
GITHUB_TOKEN = os.getenv("GH_TOKEN")
# Official 2026 GitHub Models API endpoint
AI_URL = "https://models.inference.ai.azure.com/chat/completions"

def ask_ai(finding_desc, file_content):
    """Calls GitHub Models API (GPT-4o) for remediation."""
    headers = {
        "Authorization": f"Bearer {GITHUB_TOKEN}",
        "Content-Type": "application/json"
    }
    
    prompt = (
        f"You are a Mobile Security Expert. Fix the following vulnerability: {finding_desc}\n"
        f"Full file content provided below. Return ONLY the entire corrected source code. "
        "Do not include markdown code blocks (no ```), no explanations, and no notes."
    )
    
    payload = {
        "model": "gpt-4o",
        "messages": [
            {"role": "system", "content": "You are a secure coding assistant."},
            {"role": "user", "content": f"{prompt}\n\nCODE:\n{file_content}"}
        ],
        "temperature": 0.1
    }
    
    response = requests.post(AI_URL, headers=headers, json=payload)
    response.raise_for_status()
    return response.json()['choices'][0]['message']['content'].strip()

def process_issue(issue):
    file_path = issue['file_path']
    desc = issue['description']
    
    print(f"--- Processing: {file_path} ---")
    
    # 1. Prepare unique branch
    unique_id = os.urandom(2).hex()
    branch_name = f"ai-fix/{unique_id}"
    subprocess.run(["git", "checkout", "main"])
    subprocess.run(["git", "checkout", "-b", branch_name])
    
    # 2. Get AI Fix
    with open(file_path, 'r') as f:
        original_code = f.read()
    
    try:
        fixed_code = ask_ai(desc, original_code)
        
        # 3. Push empty branch to GitHub (to create the PR space)
        subprocess.run(["git", "push", "origin", branch_name, "--force"])
        
        # 4. Create Draft PR using GitHub CLI
        pr_title = f"üõ°Ô∏è [AI Suggestion] Fix: {desc[:50]}..."
        pr_body = (
            f"### MobSF Security Finding\n"
            f"**File:** `{file_path}`\n"
            f"**Issue:** {desc}\n\n"
            "This PR contains a suggested fix generated by AI. "
            "Review the suggestion in the comments below."
        )
        
        pr_url = subprocess.check_output([
            "gh", "pr", "create",
            "--title", pr_title,
            "--body", pr_body,
            "--head", branch_name,
            "--draft"
        ], text=True).strip()
        
        # 5. Post the Suggested Change comment
        # We wrap the fix in the special suggestion block
        comment_body = (
            f"**ü§ñ AI Suggested Remediation:**\n"
            f"```suggestion\n{fixed_code}\n```"
        )
        
        subprocess.run(["gh", "pr", "comment", pr_url, "--body", comment_body])
        print(f"‚úÖ Created Draft PR: {pr_url}")
        
    except Exception as e:
        print(f"‚ùå Error generating fix for {file_path}: {e}")

if __name__ == "__main__":
    if not os.path.exists('mobsf_results.json'):
        print("No results found.")
        exit(0)

    with open('mobsf_results.json') as f:
        data = json.load(f)
        results = data.get('results', {})

    # Flatten findings from MobSF dictionary structure
    findings = []
    for rule_id, details in results.items():
        for f_info in details.get('files', []):
            findings.append({
                'description': details.get('metadata', {}).get('description'),
                'file_path': f_info.get('file_path')
            })

    print(f"Total findings to process: {len(findings)}")

    # For PoC safety, process the first 3 findings only
    for issue in findings[:3]:
        process_issue(issue)
        time.sleep(2) # Avoid hitting secondary rate limits
